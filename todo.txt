
20 décembre:

* Ajouter la reconnaissance dans les vidéos: https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/
* Rempacer PIL par Pillow-simd https://github.com/uploadcare/pillow-simd#pillow-simd
* Supprimer la notion de value_read/value_computed au niveau de metadata. Le rendre spécifique à CameraModel.
* Ajoute la notion de text_value / binary_value dans metadata et dans la base de données (jm/bm)
* Reconnaissance faciale :
* - Ajouter une metadata faces qui contient la liste des boîtes de personnes
* - Ajouter une metadata persons qui contient la liste des noms de personnes reconnues (box_id, name, type)

5 novembre:

* Créer des .info avec le nom d'un fichier ou répertoire dans le même répertoire. Son contenu sera utilisé pour définir un Camera Model en cas de Unknown.

9 octobre:

* Ajouter la notion de "edited": si le fichier a une date exif d'update != de la date exif de création
* Ajouter la notion de "edited-similar". Pour savoir si un fichier est similaire, utiliser le hash (qui existe actuellement).
* Créer trois sortes de répertoires différents: les -original / -edited / -edited-similar
* Pour savoir si un fichier est dupliqué: comparer simplement la taille du fichier (nombre d'octets) => devrait résoudre le problème des photos en rafales qui peuvent être prises à la même seconde ?
* Enregistrer les fichiers avec à l'intérieur du nom la date exif d'update (au lieu de création)
* ajouter une option --exclude-similar, qui ne crée pas "edited-similar"

5 septembre:

* Ajouter les THM, qui permettant parfois de retrouver le camera model des vidéos. Exemple: E:\data\photos-all\depuis-samsung-T5\photos\2006\2006_06_06: OK
* Pourquoi les avi sont en unknown ici : E:\data\photos-all\depuis-samsung-T5\photos\2012\mada - avril 2012\113___04 ? => parce qu'un fichier image du répertoire n'est pas du même appareil photo ... bizarre.
* Pour les unknown, renommer les répertoires en "Unknown~{[path][to][the][unknown][file]}~", pour garder une trace du chemin des fichiers

29 aout:

* Ne plus lancer le sig compute, il est lancer automatiquement que pour ce qui est nécessaire lors de la copie.
* Créer une étape avec barre de progression "lecture des metadonnées exif" (plutôt que ça soit implicite quand on lit les cameramodel)
* Au lieu des propagate_to_duplicates, faire la diffusion aux dupliqués à chaque mise à jour de computed_value
	compute_value du cm
		propage_to_duplicate(media_file)
	compute_value de sig
		update_date_and_sig_map()
		propagate_sig_to_duplicate(media_file)
		propagate_cm_to_duplicate(media_file) (puisqu'on a mis à jour la date_and_sig_map)
* ajouter la liste des fichiers ignorés
* ajouter la liste des fichiers non copiés
* Nommer chaque fichier comme ça: 2008-08-12_11h04m12~{file0006}~1280x720 (on ajoute la taille systématiquement ... plus simple pour garder les différentes tailles)

19 aout:

* Pour l'instant, abandon des signatures pour comparer les images => remplacement par un md5 pour tout
* Suppression du calcul des miniatures (à réétudier plus tard, c'est commité donc je pourrai le récupérer dans l'historique)
* Lors de la réorganisation: si plusieurs versions, ajouter -<taille> à la fin du nom de fichier
* Suppression des json-metadata
* Ajouter un "cfm media sync <dir>" pour synchroniser avec la base (notamment retirer ce qui n'existe pas et ajouter ce qui manque, mais sans rien calculer)
* Ajouter un fichier pour lister les "ignored"
* Prendre en compte les thm, car ils permettent de connaître parfois d'où vient une vidéo
* Mettre des chemin relatif à l'endroit ou est cfm.db (pour origin/destination je peux laisser des chemins absolus. D'ailleurs je peux mettre deux colonnes éventuellement)

* Quand on lance une analyse:
	- d'abord le "cm find" (mieux de le lancer avant au cas où la copie "casse" des répertoires)
		=> à termes, séparer la récupération des metadata dans une commande à part
	- puis lancer le "sig compute" (dans un second temps car pour l'instant ça utilise la date récupérée dans le cm find)
	- Puis le "cp"
	- Puis le "org"

* Chargement en trois temps:
	* Créer d'abord tous les MediaFile à partir de la base de données complète
	* Synchroniser ensuite (dans la GUI, le faire en arrière plan): charger les fichiers qui n'ont pas été chargés, supprimer ceux qui n'existent plus.
	* Calculer les signatures et les metadonnées (dans la GUI, le faire en arrière plan)
	* Enregistrer la base de données
 
* Ajouter dans la base de données une table globale avec différents status:
	* Toutes les signatures ont été calculées tel moment
	* Toutes les metadonnées ont été lues à tel moment

* page intéressante sur les hash: https://fullstackml.com/wavelet-image-hash-in-python-3504fdd282b5
* Pour extraire des images de vidéos: https://pypi.org/project/moviepy/

exemples:
	* https://medium.com/@abderrahimremuos/steps-to-create-thumbnails-from-video-in-python-using-moviepy-3eab81b6ad8c
	* https://github.com/flavioribeiro/video-thumbnail-generator/blob/master/generator

Pour ensuite éventuellement créer un gif/png animé: https://note.nkmk.me/en/python-pillow-gif/

* GUI: trouver de belles icones et ajouter correctement les resources au projet